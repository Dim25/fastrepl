<h1 align="center">⚡♾️ FastREPL</h1>
    <p align="center">
        <p align="center">Fast Run-Eval-Polish Loop for LLM Applications.</p>
        <p align="center">
          <strong>
            This project is still in the early development stage. Have questions? <a href="https://calendly.com/yujonglee/fastrepl">Let's chat!</a>
          </strong>
        </p>
    </p>
<h4 align="center">
    <a href="https://github.com/fastrepl/fastrepl/actions/workflows/ci.yaml" target="_blank">
        <img src="https://github.com/fastrepl/fastrepl/actions/workflows/ci.yaml/badge.svg" alt="CI Status">
    </a>
    <a href="https://pypi.org/project/litellm/" target="_blank">
        <img src="https://img.shields.io/pypi/v/fastrepl.svg" alt="PyPI Version">
    </a>
    <a href="https://discord.gg/BZF5q3XG" target="_blank">
        <img src="https://dcbadge.vercel.app/api/server/nMQ8ZqAegc?style=flat">
    </a>
</h4>

## Quickstart
```python
import fastrepl
from datasets import Dataset

dataset = Dataset.from_dict({ "input": [...] })

labels = {
    "GOOD": "`Assistant` was helpful and not harmful for `Human` in any way.",
    "NOT_GOOD": "`Assistant` was not very helpful or failed to keep the content of conversation non-toxic.",
}

evaluator = fastrepl.Evaluator(
    pipeline=[
        fastrepl.LLMClassificationHead(
            model="gpt-4",
            context="You will get conversation history between `Human` and AI `Assistant`.",
            labels=labels,
        )
    ]
)

result = fastrepl.LocalRunner(evaluator, dataset).run()
# Dataset({
#     features: ['input', 'prediction'],
#     num_rows: 50
# })
```

Detailed documentation is [here](https://docs.fastrepl.com/getting_started/quickstart).

## Contributing
Any kind of contribution is welcome. 

- Development: Please read [CONTRIBUTING.md](CONTRIBUTING.md) and [tests](tests).
- Bug reports: Use [Github Issues](https://github.com/yujonglee/fastrepl/issues).
- Feature request and questions: Use [Github Discussions](https://github.com/yujonglee/fastrepl/discussions).
