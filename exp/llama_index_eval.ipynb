{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq llama_index==\"0.8.2\" pydantic==\"1.10.12\" nltk\n",
    "# https://gpt-index.readthedocs.io/en/stable/core_modules/supporting_modules/evaluation/usage_pattern.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleWebPageReader,\n",
    "    ServiceContext,\n",
    "    LLMPredictor,\n",
    ")\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "urls = [\"http://paulgraham.com/greatwork.html\"]\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(urls)\n",
    "\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"gpt-4\"))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents, service_context=service_context\n",
    ")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES ['YES', 'NO']\n"
     ]
    }
   ],
   "source": [
    "from llama_index.evaluation import ResponseEvaluator\n",
    "\n",
    "# https://gpt-index.readthedocs.io/en/v0.6.33/how_to/evaluation/evaluation.html#binary-evaluation\n",
    "evaluator = ResponseEvaluator(service_context=service_context)\n",
    "response = query_engine.query(\"How to do great work?\")\n",
    "\n",
    "eval_result1 = evaluator.evaluate(response)\n",
    "eval_result2 = evaluator.evaluate_source_nodes(response)\n",
    "print(str(eval_result1), str(eval_result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES ['YES', 'YES']\n"
     ]
    }
   ],
   "source": [
    "from llama_index.evaluation import QueryResponseEvaluator\n",
    "\n",
    "evaluator = QueryResponseEvaluator(service_context=service_context)\n",
    "\n",
    "query = \"How to do great work?\"\n",
    "response = query_engine.query(query)\n",
    "\n",
    "eval_result1 = evaluator.evaluate(query, response)\n",
    "eval_result2 = evaluator.evaluate_source_nodes(query, response)\n",
    "print(str(eval_result1), str(eval_result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the three qualities that the work you choose needs to have according to the author?\n",
      "How does the author suggest figuring out what to work on?\n",
      "What are the four steps the author outlines for doing great work?\n",
      "Why does the author emphasize the importance of working on something you're deeply interested in?\n",
      "How does the author suggest making yourself a big target for luck?\n"
     ]
    }
   ],
   "source": [
    "# Question generation (Can be paired with eval above)\n",
    "\n",
    "from llama_index.evaluation import DatasetGenerator\n",
    "\n",
    "data_generator = DatasetGenerator.from_documents(documents)\n",
    "eval_questions = data_generator.generate_questions_from_nodes(num=5)\n",
    "\n",
    "for q in eval_questions:\n",
    "    print(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
