{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install fastrepl\n",
    "```\n",
    "\n",
    "You can find all releases [here](https://pypi.org/project/fastrepl).\n",
    "\n",
    "## Setup FastREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using it in a script\n",
    "import fastrepl\n",
    "\n",
    "# When using it in a notebook\n",
    "import fastrepl.repl as fastrepl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "We will use [daily_dialog](https://huggingface.co/datasets/daily_dialog) from Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input'],\n",
       "    num_rows: 120\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"daily_dialog\", split=\"test\")\n",
    "ds = ds.shuffle(4)\n",
    "ds = ds.select(range(120))\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    return re.sub(r\"\\s+([,.'!?])\", r\"\\1\", text.strip())\n",
    "\n",
    "\n",
    "def get_input(row):\n",
    "    msgs = [clean(msg) for msg in row[\"dialog\"]]\n",
    "    row[\"input\"] = \"\\n\".join(msgs)\n",
    "    return row\n",
    "\n",
    "\n",
    "ds = ds.map(get_input, remove_columns=[\"dialog\", \"act\", \"emotion\"])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluator\n",
    "\n",
    "Here, we are doing simple classifiction, but there are two interesting points.\n",
    "\n",
    "1. You can pass nearly any model for evaluation. (Thanks to [LiteLLM](https://github.com/BerriAI/litellm)).\n",
    "2. **`fastrepl` enhances accuracy by reducing [bias](/guides/dealing_with_bias.md)**. `position_debias_strategy` is one example, which ensures that the order of labels doesn't affect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = fastrepl.Evaluator(\n",
    "    pipeline=[\n",
    "        fastrepl.LLMClassificationHead(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            context=\"You will receive casual conversation between two people.\",\n",
    "            labels={\n",
    "                \"FUN\": \"at least one of the two people try to be funny and entertain.\",\n",
    "                \"NOT_FUN\": \"given conversation lacks humor or entertainment value.\",\n",
    "            },\n",
    "            position_debias_strategy=\"consensus\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluator\n",
    "\n",
    "Here are some notes about running the evaluator:\n",
    "\n",
    "1. `ThreadPool` is used to make it faster (controlled by the `NUM_THREADS` [environment variable](/getting_started/env.md)).\n",
    "2. Any errors from different LLM providers are properly handled and retried with backoff if necessary.\n",
    "3. Since we passed `num=2` to `run()`, it will execute same evaluation twice, and return two results. If there are high inconsistency between the two, you'll see [InconsistentPredictionWarning](/miscellaneous/warnings_and_errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04f7adeea214949b31b70326946cbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/yujonglee/dev/fastrepl/fastrepl/fastrepl/warnings.py:24: CompletionTruncatedWarning: B | \n",
       "https://docs.fastrepl.com/miscellaneous/warnings_and_errors#completiontruncated\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/yujonglee/dev/fastrepl/fastrepl/fastrepl/warnings.py:24: CompletionTruncatedWarning: B | \n",
       "https://docs.fastrepl.com/miscellaneous/warnings_and_errors#completiontruncated\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/yujonglee/dev/fastrepl/fastrepl/fastrepl/warnings.py:24: CompletionTruncatedWarning: A | \n",
       "https://docs.fastrepl.com/miscellaneous/warnings_and_errors#completiontruncated\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/yujonglee/dev/fastrepl/fastrepl/fastrepl/warnings.py:24: CompletionTruncatedWarning: A | \n",
       "https://docs.fastrepl.com/miscellaneous/warnings_and_errors#completiontruncated\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'prediction'],\n",
       "    num_rows: 120\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = fastrepl.LocalRunner(evaluator=evaluator, dataset=ds).run(num=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting point to note is that, due to the `position_debias_strategy=\"consensus\"`, if the order of the labels affects the result, `fastrepl` will return `None`. We are be returning more meaningful value in the later version of `fastrepl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "first_result = [row[0] for row in result[\"prediction\"]]\n",
    "second_result = [row[1] for row in result[\"prediction\"]]\n",
    "\n",
    "print(first_result.count(None))\n",
    "print(second_result.count(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got some numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46464646464646464\n",
      "0.43373493975903615\n"
     ]
    }
   ],
   "source": [
    "def metric(result):\n",
    "    f = result.count(\"FUN\")\n",
    "    nf = result.count(\"NOT_FUN\")\n",
    "    return f / (f + nf)\n",
    "\n",
    "\n",
    "print(metric(first_result))\n",
    "print(metric(second_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
