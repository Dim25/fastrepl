# Model Graded Evaluation
There are some metric like [`rouge`](https://huggingface.co/spaces/evaluate-metric/rouge), but for most cases, especially in business, you'll need to evaluate more complex aspects of your model.

**TODO: We will have detailed survey over recent papers in the future.**

## Resources
- [OpenAI content moderation](https://openai.com/blog/using-gpt-4-for-content-moderation)

- [Large Model Systems Organization](https://lmsys.org/blog/2023-07-20-dataset/#agreement-calculation)

- [Large language models on wikipedia-style survey generation](https://arxiv.org/pdf/2308.10410.pdf)
    > `Figure 2: Human Evaluation Scores`

- [Style Over Substance: Evaluation Biases for Large Language Models](https://arxiv.org/abs/2307.03025)

- [Patterns for Building LLM-based Systems & Products](https://eugeneyan.com/writing/llm-patterns/#evals-to-measure-performance)

- [Judging LLM-as-a-judge with MT-Bench and Chatbot Arena](https://arxiv.org/pdf/2306.05685.pdf)

- [G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment](https://arxiv.org/pdf/2303.16634.pdf)

- [Large Language Models are not Fair Evaluators](https://arxiv.org/pdf/2305.17926.pdf)

- [The False Promise of Imitating Proprietary LLMs](https://arxiv.org/pdf/2305.15717.pdf)
    > GPT-4 may be a viable candidate to cheaply emulate human evaluations on some tasks, it also implies that LLMs may replicate some human-like cognitive biases.

- [Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation](https://arxiv.org/pdf/2304.00723.pdf)